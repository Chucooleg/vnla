description: VNLA aggrevate experiments bootstrap 14413 250 2 eu2
# experiment named vnla_time_comparisons

target:
  # which virtual cluster you belong to (msrlabs, etc.). Everyone has access to "msrlabs".
  vc: msrlabs
  # physical cluster to use (cam, gcr, rr1, rr2) or Azure clusters (eu1, eu2, etc.)
  cluster: eu2

environment:
  image: philly/jobs/test/pytorch:pytorch1.2.0-py36-mattersim
  registry: phillyregistry.azurecr.io

  setup:
    - pip install scikit-learn --user
    - python -m pip install networkx==2.3 --user
    - CUDA_VISIBLE_DEVICES=0
    # - pip install tensorboard --user
    # - CUDA_VISIBLE_DEVICES=0,1,2,3
    # - pip install ipdb --user

storage:
  input1:
    storage_account_name: msrairesidentssa4
    container_name: matterport3d
    mount_dir: /mnt/matterport3d
    # local_dir: /home/hoyeung/blob_matterport3d/
  output:
    storage_account_name: msrairesidentssa4
    container_name: experiment-results
    mount_dir: /mnt/experiment-results-philly/
    # local_dir: /home/hoyeung/blob_experiments/

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: $CONFIG_DIR/

# data:
#   data upload is not required for this example

# seed list
# 10 [42, 677, 848, 163, 620, 511, 102, 158, 2, 204]
# 20 + [471, 154, 220, 748, 623, 47, 882, 136, 315, 48]

# list of jobs to run, we run 2 jobs in this example
jobs:
  # name must be unique across the jobs
- name: data_14413_heads_2_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.5 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.75 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_1" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 1.0 -sample_head 1 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.5_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.75_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_1.0_headlayers_2_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 2 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_2_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_2_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 2 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_4_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_4_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 4 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_8_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_8_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 8 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.5_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.5 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_0.75_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 0.75 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_heads_16_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_heads_16_1.0_headlayers_4_batch_size_250_train_batch_size_512_sample_head_0" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 1 -n_ensemble 16 -bernoulli_probability 1.0 -sample_head 0 -num_q_predictor_layers 4 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42


- name: data_14413_nobootstrap_batch_size_250_train_batch_size_512
  sku: G1
  command:
  - cd tasks/VNLA/scripts/ && bash train_experiments.sh "20200229_philly_aggrevate_bootstrapping_14413_250_2" "data_14413_nobootstrap_batch_size_250_train_batch_size_512" "configs/experiment.json" -data_suffix small_thirty_goals_anylength -bootstrap 0 -batch_size 250 -train_batch_size 512 -loss_function l2 -lr 0.0001 -beta_decay_rate 0.8 -min_history_to_learn 5000 -save_every 10000 -log_every 1000 -plot_to_philly 0 -seed 42